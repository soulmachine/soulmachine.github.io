<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Hadoop | soulmachine]]></title>
  <link href="http://www.soulmachine.me/blog/categories/hadoop/atom.xml" rel="self"/>
  <link href="http://www.soulmachine.me/"/>
  <updated>2015-07-23T13:53:56-07:00</updated>
  <id>http://www.soulmachine.me/</id>
  <author>
    <name><![CDATA[soulmachine]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Debug Hadoop Applications With IntelliJ]]></title>
    <link href="http://www.soulmachine.me/blog/2015/01/30/debug-hadoop-applications-with-intellij/"/>
    <updated>2015-01-30T12:15:18-08:00</updated>
    <id>http://www.soulmachine.me/blog/2015/01/30/debug-hadoop-applications-with-intellij</id>
    <content type="html"><![CDATA[<p>In my previous blog, I explained how to <a href="http://www.soulmachine.me/blog/2015/01/29/create-a-hadoop-compilation-and-development-environment/">Create a Hadoop Compilation and Development Environment</a> so that you can build the Hadoop source code you get from the Apache Hadoop git repository.</p>

<p>However, not everyone need to dig into the source code, normally more people will just call the Hadoop APIs to write a MapReduce program. When you write a MapReduce program, you rarely get it right for one time, then you need to debug your code.</p>

<p>This time I&rsquo;ll show you how to debug your Hadoop applications using the IntelliJ IDE.</p>

<p><strong>Environment</strong>: CentOS 6.6, Oracle JDK 1.7.0_75, Maven 3.2.5, IntelliJ Idea 14.0.3</p>

<h2>1. Create a MapReduce Maven project</h2>

<p>First we need to create a MapReduce program to debug. Let&rsquo;s use the simplest example, WordCount, for demonstration.  The source code is here <a href="http://wiki.apache.org/hadoop/WordCount">WordCount &ndash; Hadoop Wiki</a>.</p>

<h3>1.1 Generate the Maven project</h3>

<p>Use the <code>mvn</code> command to generate the scaffolding for the project.</p>

<pre><code>mvn archetype:generate -DgroupId=me.soulmachine -DartifactId=wordcount -DarchetypeArtifactId=maven-archetype-quickstart -DinteractiveMode=false
</code></pre>

<p>Delete the <code>src/test/java/me/soulmachine/AppTest.java</code> file, as it will not be used in this example, and rename the <code>src/main/java/me/soulmachine/App.java</code> file to <code>WordCount.java</code>.</p>

<!--more-->


<p>Now the structure of the project is as the following:</p>

<pre><code>tree ./wordcount
wordcount/
├── pom.xml
└── src
    ├── main
    │   └── java
    │       └── me
    │           └── soulmachine
    │               └── WordCount.java
    └── test
        └── java
            └── me
                └── soulmachine
</code></pre>

<h3>1.2 Write the code</h3>

<p>Rename the <code>src/main/java/me/soulmachine/App.java</code> file to <code>WordCount.java</code>, edit the file and copy and paste the code from <a href="http://wiki.apache.org/hadoop/WordCount">WordCount &ndash; Hadoop Wiki</a>, remember to change the first line from <code>package org.myorg</code> to <code>package me.soulmachine</code>.</p>

<p>I made some improvements to this code,  check it out:</p>

<p><div><script src='https://gist.github.com/a8130aa4983f2036b3bf.js?file=WordCount.java'></script>
<noscript><pre><code>package me.soulmachine;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.conf.Configured;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;
import org.apache.hadoop.util.Tool;
import org.apache.hadoop.util.ToolRunner;

import java.io.IOException;
import java.util.StringTokenizer;


public class WordCount extends Configured implements Tool {

  public static class MyMapper extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt; {
    private static final IntWritable ONE = new IntWritable(1);
    private final transient Text word = new Text();

    @Override
    public void map(final LongWritable key, final Text value, final Context context)
        throws IOException, InterruptedException {
      final String line = value.toString();
      final StringTokenizer tokenizer = new StringTokenizer(line);
      while (tokenizer.hasMoreTokens()) {
        word.set(tokenizer.nextToken());
        context.write(word, ONE);
      }
    }
  }


  public static class MyReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {

    @Override
    public void reduce(final Text key, final Iterable&lt;IntWritable&gt; values, final Context context)
        throws IOException, InterruptedException {
      int sum = 0;
      for (final IntWritable val : values) {
        sum += val.get();
      }
      context.write(key, new IntWritable(sum));
    }
  }


  @Override
  public int run(final String[] args) throws Exception {
    final Configuration conf = this.getConf();
    final Job job = Job.getInstance(conf, &quot;Word Count&quot;);
    job.setJarByClass(WordCount.class);

    job.setMapperClass(MyMapper.class);
    job.setReducerClass(MyReducer.class);

    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(NullWritable.class);
    job.setInputFormatClass(TextInputFormat.class);
    job.setOutputFormatClass(TextOutputFormat.class);

    FileInputFormat.addInputPath(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));

    return job.waitForCompletion(true) ? 0 : 1;
  }

  public static void main(final String[] args) throws Exception {
    final int returnCode = ToolRunner.run(new Configuration(), new WordCount(), args);
    System.exit(returnCode);
  }
}
</code></pre></noscript></div>
</p>

<h3>1.3 Edit the pom.xml file</h3>

<p>The content of the <code>pom.xml</code> file is as the following:</p>

<pre><code>&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd"&gt;
  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
  &lt;groupId&gt;me.soulmachine&lt;/groupId&gt;
  &lt;artifactId&gt;wordcount&lt;/artifactId&gt;
  &lt;packaging&gt;jar&lt;/packaging&gt;
  &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
  &lt;name&gt;wordcount&lt;/name&gt;
  &lt;url&gt;http://maven.apache.org&lt;/url&gt;

  &lt;properties&gt;
    &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
    &lt;hadoop.version&gt;2.6.0&lt;/hadoop.version&gt;
  &lt;/properties&gt;

  &lt;dependencies&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
      &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;
      &lt;version&gt;${hadoop.version}&lt;/version&gt;
    &lt;/dependency&gt;
  &lt;/dependencies&gt;

  &lt;build&gt;
    &lt;plugins&gt;
      &lt;plugin&gt;
        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
        &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;
        &lt;configuration&gt;
          &lt;archive&gt;
            &lt;manifest&gt;
              &lt;mainClass&gt;me.soulmachine.WordCount&lt;/mainClass&gt;
            &lt;/manifest&gt;
          &lt;/archive&gt;
        &lt;/configuration&gt;
      &lt;/plugin&gt;
    &lt;/plugins&gt;
  &lt;/build&gt;
&lt;/project&gt;
</code></pre>

<h3>1.4 Compile</h3>

<pre><code>mvn clean package
</code></pre>

<p>If this step succeeds, move to the next step.</p>

<h2>2. Debug WordCount in IntelliJ Idea</h2>

<h3>2.1 Open the project in IntelliJ Idea</h3>

<p>Launch IntelliJ Idea, click <code>File-&gt;Open</code> and open the <code>pom.xml</code>, thus you can import the project into IntelliJ Idea.</p>

<h3>2.2 Create a Run/Debug Configuration</h3>

<p>Select the project &ldquo;WordCount&rdquo;, Click menu <code>Run-&gt;Edit Configurations ...</code>,</p>

<ol>
<li>Click the button on the right of <code>Main Class</code> and select <code>me.soulmachine.WordCount</code> as the main class.</li>
<li>Set <code>Program Arguments</code> to <code>input/ output</code>, and create a directory named <code>input</code> in the project directory, no need to create the <code>output/</code> directory</li>
<li>Leave other fields as default.</li>
<li>Click <code>OK</code> and finish.</li>
</ol>


<p><img src="/images/2015-01-29-intellij-debug-configuration.png"></p>

<h3>2.3 Run the program</h3>

<ol>
<li>Create a text file named <code>file1.txt</code> in the <code>input/</code> directory and set its content as <code>Hello World Bye World</code>, create another text file named <code>file2.txt</code> and set its content to <code>Hello Hadoop Goodbye Hadoop</code>.</li>
<li>Click menu <code>Run-&gt;Run 'Word Count'</code>, after it finishes, you will see a fold named <code>output/</code> in the project root directory and there are two files named <code>part-r-00000</code> and <code>_SUCCESS</code>.</li>
</ol>


<h3>2.4 Debug the program</h3>

<p>Set a break point in the <code>main</code> function and click menu <code>Run-&gt;Debug 'Word Count'</code>, then you can debug the code step by step.</p>

<h2>Reference</h2>

<ol>
<li><a href="http://vichargrave.com/debugging-hadoop-applications-with-intellij/">Debugging Hadoop Applications with IntelliJ | VicHargrave.com</a></li>
<li><a href="http://wiki.apache.org/hadoop/WordCount">WordCount &ndash; Hadoop Wiki</a></li>
<li><a href="http://maven.apache.org/guides/getting-started/maven-in-five-minutes.html">Maven in 5 Minutes</a></li>
<li><a href="http://azure.microsoft.com/nl-nl/documentation/articles/hdinsight-develop-deploy-java-mapreduce/">Develop Java MapReduce programs for Hadoop in HDInsight | Azure</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Create a Hadoop Compilation and Development Environment]]></title>
    <link href="http://www.soulmachine.me/blog/2015/01/29/create-a-hadoop-compilation-and-development-environment/"/>
    <updated>2015-01-29T11:56:41-08:00</updated>
    <id>http://www.soulmachine.me/blog/2015/01/29/create-a-hadoop-compilation-and-development-environment</id>
    <content type="html"><![CDATA[<p>If you want to read the source code of Hadoop and dig into the internals of Hadoop, then you need to know how to compile the source code and use IDEs (such as Eclipse or IntelliJ Idea) to open the projects. This blog will introduce you how to create a Hadoop build and development environment.</p>

<p><strong>Environment</strong>: CentOS 6.6,  Oracle JDK 1.7.0_75</p>

<h2>1. Install Oracle JDK 7</h2>

<pre><code>Download jdk-7u75-linux-x64.rpm
sudo yum localinstall -y ./jdk-7u75-linux-x64.rpm
</code></pre>

<p>For now if you use JDK 8 to compile the source code of Hadoop, it will fail because the javadoc  in Java 8 is considerably more strict than the one in earlier version, see more detailes <a href="http://blog.joda.org/2014/02/turning-off-doclint-in-jdk-8-javadoc.html">here</a></p>

<h2>2. Install Maven</h2>

<pre><code>wget http://mirrors.gigenet.com/apache/maven/maven-3/3.2.5/binaries/apache-maven-3.2.5-bin.tar.gz
sudo tar -zxf apache-maven-3.2.5-bin.tar.gz -C /opt
sudo vim /etc/profile
export M2_HOME=/opt/apache-maven-3.2.5
export PATH=$M2_HOME/bin:$PATH
</code></pre>

<h2>3. Install FindBugs(Optional)</h2>

<pre><code>wget http://iweb.dl.sourceforge.net/project/findbugs/findbugs/3.0.0/findbugs-3.0.0.tar.gz
sudo tar -zxf findbugs-3.0.0.tar.gz -C /opt
sudo vim /etc/profile
export FB_HOME=/opt/findbugs-3.0.0
export PATH=$FB_HOME/bin:$PATH
</code></pre>

<p>If you want to run <code>mvn compile findbugs:findbugs</code> then you need to install FindBugs.</p>

<!-- more -->


<h2>4. Install build tools</h2>

<pre><code>sudo yum install -y gcc-c++ cmake autoconf automake
</code></pre>

<h2>5. Install native libraries packages</h2>

<pre><code>sudo yum -y install  gcc-c++ lzo-devel  zlib-devel libtool openssl-devel
</code></pre>

<p>Optional:</p>

<pre><code>sudo yum install -y snappy-devel
sudo yum install -y svn
</code></pre>

<p>During the process of compilation, it will throw out some warning messages if there is no <code>svn</code> command.</p>

<h2>5. Install Protobuf</h2>

<pre><code>wget https://protobuf.googlecode.com/files/protobuf-2.5.0.tar.gz
tar -zxf protobuf-2.5.0.tar.gz
cd protobuf-2.5.0
./configure
make
sudo make install
rm -rf ./protobuf-2.5.0
rm ./protobuf-2.5.0.tar.gz
</code></pre>

<p><strong>NOTE</strong>: The Protobuf version must be exactly 2.5.0, or the compilation will fail.</p>

<h2>6. Download the source code</h2>

<pre><code>git clone git@github.com:apache/hadoop.git
</code></pre>

<h2>7. Compile</h2>

<p>Create binary distribution with native code and without documentation.</p>

<pre><code>mvn clean package -Pdist,native -Dtar -DskipTests -Drequire.snappy -Drequire.openssl
</code></pre>

<h2>8. Install IntelliJ Idea</h2>

<pre><code>wget http://download-cf.jetbrains.com/idea/ideaIC-14.0.3.tar.gz
sudo tar -zxf ideaIC-14.0.3.tar.gz -C /opt
Launch IntelliJ Idea, Create Desktop Entry
</code></pre>

<h2>9. Open projects in IntelliJ Idea</h2>

<p>First you need to run</p>

<pre><code>mvn install -DskipTests
</code></pre>

<p>Since some submodules of Hadoop depend on other submodules,  so you need to run <code>mvn install -DskipTests</code> to copy jars of Hadoop submodules to local <code>$HOME/.m2</code> , so that Maven won&rsquo;t download them from Internet. If you omit this step, Maven will try to download them from public Maven repository and will fail, because the newest version of Hadoop jars are not available in public Maven repository yet.</p>

<p>Then click <code>File-&gt;Open</code> to open the <code>pom.xml</code> in the root directory of Hadoop repo.</p>

<p><strong>Note</strong>: Don&rsquo;t use <code>mvn idea:idea</code> to generate IntelliJ Idea projects first , IntelliJ Idea can handle pom.xml quite well, besides, the <a href="http://maven.apache.org/plugins/maven-idea-plugin/">&ldquo;Maven IDEA Plugin&rdquo;</a> has already RETIRED.</p>

<h2>10. Increase the memory for IntelliJ Idea(Optional)</h2>

<p>There are many classes in Hadoop source code, if your IntelliJ hangs and doesn&rsquo;t respond from time to time, then you can try to give more memory to IntelliJ Idea by modifying the file <code>idea64.vmoptions</code> in the installation directory. Example below:</p>

<pre><code>-Xms128m
-Xmx4096m
-XX:MaxPermSize=1024m
</code></pre>

<h2>Reference</h2>

<ol>
<li><a href="http://wiki.apache.org/hadoop/HowToContribute">HowToContribute</a></li>
<li><a href="https://github.com/apache/hadoop/blob/trunk/BUILDING.txt">BUILDING.txt</a></li>
<li><a href="http://vichargrave.com/create-a-hadoop-build-and-development-environment-for-hadoop/">Create a Hadoop Build and Development Environment</a></li>
<li><a href="http://blog.cloudera.com/blog/2014/06/how-to-create-an-intellij-idea-project-for-apache-hadoop/">How-to: Create an IntelliJ IDEA Project for Apache Hadoop</a></li>
</ol>


<p>In my next blog, I&rsquo;ll explain how to <a href="http://www.soulmachine.me/blog/2015/01/30/debug-hadoop-applications-with-intellij/">Debug Hadoop Applications with IntelliJ</a></p>
]]></content>
  </entry>
  
</feed>
